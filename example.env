# Пути
VOSK_MODEL_PATH=./vosk-model
LLAMA_SERVER_PATH=./llama.cpp/build/bin/llama-server
MODEL_PATH=./models/gemma-2-9b-it-Q4_K_M.gguf
AUDIO_TEMP_DIR=./temp_audio
LOGS_DIR=./chat_logs

# Количество потоков для работы модели llama
LLAMA_THREADS=8

# Время ежедневной сводки (формат HH:MM)
DAILY_SUMMARY_TIME=23:00

# Настройки бота
BOT_TOKEN=##################################
MAX_HISTORY_LENGTH=5
MAX_RESPONSE_TOKENS=768
TARGET_CHUNK_SIZE=1500

SYSTEM_PROMPT="Вы универсальный Чат-бот."

# Настройки модели
MAX_CTX_SIZE=2048
GENERATION_TEMP=0.7
SUMMARY_TEMP=0.3
REPEAT_PENALTY=1.1
BATCH_SIZE=512
GENERATION_TIMEOUT=300
LLAMA_SERVER_HOST=127.0.0.1
LLAMA_SERVER_PORT=8080
